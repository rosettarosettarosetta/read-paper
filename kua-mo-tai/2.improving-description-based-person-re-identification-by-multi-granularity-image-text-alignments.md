# 2.Improving Description-based Person Re-identification by Multi-granularity Image-text Align

## abstract

所有属于单个类别的样本（**细粒度问题**）使得这个任务比传统的图像-描述匹配任务更加困难。

在本文中，我们提出了一种**多粒度图像-文本对齐（MIA）**模型，以减轻基于描述的人物重识别中的跨模态细粒度问题，以便更好地评估相似性。

以层次方式进行了三种不同粒度的对齐，即全局-**全局对齐**、全局-**局部对齐**和局部-局部对齐。

全局-全局对齐在全局对比（GC）模块中用于匹配图像和描述的全局上下文

全局-局部对齐在关系引导的全局-局部对齐（RGA）模块中利用局部组件与全局上下文之间的潜在关系，以突出可区分的组件并自适应地消除不相关的组件。

对于局部-局部对齐，我们在双向细粒度匹配（BFM）模块中将视觉人体部位与名词短语进行匹配。

## . INTRODUCTION

**人物重识别**（Re-id）：很难区分

处理：外部线索（例如姿势）        不幸的是，基于描述的人物重识别数据集中没有身体部位或身体分段的注释，这使得微调或重新训练成为不可能



