# 11.2

### 两个方法:PL,CL

### Curriculum Labeling (CL)：

利用一致性，如teacher/student输出一致、数据增强后预测结果应一致

通过在每个自学习周期之前重新启动模型参数来避免[概念漂移](https://www.zhihu.com/search?q=%E6%A6%82%E5%BF%B5%E6%BC%82%E7%A7%BB\&search\_source=Entity\&hybrid\_search\_source=Entity\&hybrid\_search\_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22530860794%22%7D)



半监督学习的一个必要条件是输入空间上潜在的边际数据分布 p(x) 包含[后验分布](https://www.zhihu.com/search?q=%E5%90%8E%E9%AA%8C%E5%88%86%E5%B8%83\&search\_source=Entity\&hybrid\_search\_source=Entity\&hybrid\_search\_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22433751531%22%7D) p(y|x) 的信息.

p(x)为输入样本的分布      p(y|x) 表示在给定某个样本的情况下，得到其所属某个类的概率（后演概率）

我们可以使用未标记的数据来获得关于 p(x) 的信息，从而获得关于 p(y|x) 的信息。



主要思想：对于同一样本经过不同的变换或扰动后，网络对变换（扰动）前后的输出应是相似的。

基于假设：_smoothness assumption：对于x_,x′∈X 并且非常的接近，那么他们所对应的标签 y,y′ 是相同的。

### PL：伪标签

利用已有全监督模型生成伪标签

<figure><img src="../.gitbook/assets/image.png" alt=""><figcaption></figcaption></figure>

伪标签使用带有 Dropout 的微调阶段，可以将预训练的网络以有监督的方式同时使用标记和未标记的数据进行训练。

流程：

* 将有标签部分数据分为两份：train\_set&[validation\_set](https://www.zhihu.com/search?q=validation\_set\&search\_source=Entity\&hybrid\_search\_source=Entity\&hybrid\_search\_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22116065447%22%7D)，并训练出最优的model1
* 用model1对未知标签数据(test\_set)进行预测，给出伪标签结果pseudo-labeled
* 将train\_set中抽取一部分做新的validation\_set，把[剩余部分](https://www.zhihu.com/search?q=%E5%89%A9%E4%BD%99%E9%83%A8%E5%88%86\&search\_source=Entity\&hybrid\_search\_source=Entity\&hybrid\_search\_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22116065447%22%7D)与[pseudo-labeled](https://www.zhihu.com/search?q=pseudo-labeled\&search\_source=Entity\&hybrid\_search\_source=Entity\&hybrid\_search\_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22116065447%22%7D)部分融合作为新的train\_set，训练出最优的model2
* 再用model2对未知标签数据(test\_set)进行预测，得到最终的final result label





FixMatch





## REFERENCR:

1. CL 基础讲解

{% embed url="https://zhuanlan.zhihu.com/p/433751531" %}

2\.



