---
description: >-
  https://docs.google.com/viewerng/viewer?url=https://openaccess.thecvf.com/content_cvpr_2017/papers/Li_Person_Search_With_CVPR_2017_paper.pdf
---

# 1.Person Search with Natural Language Description

## 1.Person Search with Natural Language Description

### abstract

提出了一种具有**门控神经注意机制**（Gated Neural Attention）的循环神经网络（RNN）模型，以建立在人员搜索上的最新性能

建立了"CUHK人员描述数据集"（CUHK-PEDES）

### 介绍

#### 现有技术

根据查询的模态，现有的人员搜索方法主要可以分为**基于图像查询**和**基于属性查询**两种。

基于图像查询：它要求至少提供被查询人员的一张照片

基于属性的查询：即使使用了详尽的属性集，为大规模的人员图像数据集标注这些属性也是昂贵的。

#### 本文

提出使用自然语言描述来搜索人员

\
门控神经注意机制（Gated Neural Attention，GNA）的循环神经网络（RNN）用于人员搜索。GNA-RNN接受一个描述句子和一个人员图像作为输入，并输出它们之间的相似度。

句子被输入到**a word-LSTM**中，逐字逐字地处理。在每个单词处，LSTM为各个视觉单元生成单元级别的注意力，每个注意力决定了输入图像中是否存在某些人员语义属性或视觉模式。视觉单元的注意机制对不同单词的不同单元的贡献进行加权。

我们还学习了用于自适应单词级权重的单词级门控。最终的相似度是通过对所有单元在所有单词上的响应进行平均得到的。

### 1.1. Related work

CNN-RNN模型，将图像和细粒度视觉描述联合嵌入到相同的特征空间以进行零样本学习。文本到图像检索可以通过在嵌入空间中计算距离来进行。

介绍了一些现有的模型手段

### Benchmark for person search with natural language description

数据集介绍

### 2.1. Dataset statistics

至少15个词的句子来描述给定图像中的所有重要特征。

### 2.2. User study

这9张相似图像是通过LOMO+XQDA \[24]方法从整个数据集中选择的，这是一种用于人员再识别的先进方法。

基于我们收集的语言注释，我们进行了用户研究，以研究以下内容：1）语言描述与属性相比的表达能力，2）句子数量和句子长度方面的表达能力，3）不同词汇类型的表达能力。这些研究为我们提供了了解这个新问题以及在设计神经网络时的指导。

#### **语言 vs. 属性**

语言描述比属性更精确和有效地描述人员

#### **句子数量和长度**

句子越长，用户检索正确图像的难度越小

#### **词汇类型**

名词提供了最多的信息，其次是形容词，而动词携带的信息最少。

这项研究中，句子中的名词、动词或形容词在提供给工作者之前被屏蔽掉。

### GNA-RNN model for pedestrian search

GNA-RNN网络模型由一个视觉子网络和一个语言子网络组成。

语言子网络是一个带有长短期记忆（LSTM）单元的递归神经网络（RNN），它以单词和图像作为输入。在每个单词处，它输出单元级别的注意力和单词级别的门来加权来自视觉子网络的视觉单元。单元级别的注意力根据输入单词确定应该更加关注哪些视觉单元。单词级别的门加权不同单词的重要性。所有单元的激活通过单元级别的注意力和单词级别的门进行加权，然后汇总以生成最终的相关性。

### 3.1. Visual units

视觉子网络将调整大小为256×256的人物图像作为输入。它具有与VGG-16网络相同的底层结构，并在“drop7”层添加了两个512单元的全连接层，以生成512个视觉单元

通过整个网络的联合训练，视觉单元的语义含义会自动捕捉必要的语义概念

### 3.2. Attention over visual units

如果语言子网络在某个视觉单元上生成高的注意值，并且该视觉单元也具有高的响应（表示存在某种视觉概念），那么逐元素乘法将在该单词处生成高的关联度值。最终的句子-图像关联度是所有单词的关联度值at的总和，即a = ∑\_(t=1)^T at，其中T是给定句子中的单词数。

### 3.3. Word-level gates for visual units

单元级注意力和单词级门控机制都用于对每个单词的视觉单元进行加权，以获得每个单词的语言-图像关联度aˆt，

### 3.4. Training scheme

提出的GNA-RNN使用批处理随机梯度下降(end-to-end)进行训练

训练样本是从数据集中随机选择的，其中包括相应的句子-图像对作为正样本和不相应的对作为负样本。

训练过程最小化交叉熵损失函数

### 4.1. Dataset and evaluation metrics

采用top-k准确率来评估人物检索的性能。给定一个查询句子，所有测试图像根据与查询的关联度进行排名。如果任何与查询对应的人的图像在前k个图像中，则认为搜索成功。

### 4.2. Compared methods and baselines比较方法和基线

图像字幕生成、视觉问答和视觉-语义嵌入方法

每种方法都使用不同的监督信号进行训练，并采用不同的损失函数。

### 4.3. Quantitative and qualitative results

LSTM可能难以将复杂的人物描述句子编码为单个特征向量。逐词处理和比较可能更适合人物搜索问题。

{% embed url="https://docs.google.com/viewerng/viewer?url=https://openaccess.thecvf.com/content_cvpr_2017/papers/Li_Person_Search_With_CVPR_2017_paper.pdf" %}
