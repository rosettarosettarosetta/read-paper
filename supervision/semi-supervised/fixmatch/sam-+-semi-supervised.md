---
description: https://arxiv.org/pdf/2312.06316.pdf
---

# 😖 SAM + Semi-Supervised



## 摘要&#x20;

由于与完全监督方法相比，半监督学习减少了对领域专家进行大量注释的依赖，因此受到了广泛关注，这对于通常需要领域专家进行像素/体素级标注的医学图像分割尤为重要。尽管半监督方法可以利用未标记数据提高性能，但在极度有限的标注场景下，与完全监督方法之间仍存在差距。本文提出了一种简单而高效的策略，利用Segment Anything Model (SAM) 来增强半监督医学图像分割。具体而言，利用领域知识训练的分割模型提供了定位信息，并生成输入提示用于SAM。然后，SAM生成的伪标签被用作额外的监督，辅助半监督框架的学习过程。实验结果表明，SAM的辅助显著提高了现有半监督框架的性能，特别是当只有一张或几张有标签的图像可用时。

## 介绍

医学图像分割旨在从医学图像中识别特定的解剖结构，如器官和病变。这是提供可靠的体积和形状信息，并在疾病诊断和定量分析等许多临床应用中提供帮助的基本而重要的步骤\[1,6,10]。尽管基于深度学习的方法在医学图像分割任务中表现出色，但大多数这些方法需要相对大量且高质量的注释数据进行训练，而在医学影像领域，获取大规模且经过精细标注的数据集是不切实际的，特别是只有专家才能提供可靠和准确的注释\[13]。此外，常用的医学影像模态如CT和MRI是3D体积图像，与2D图像相比，专家需要逐层切片从体积中勾勒，进一步增加了手动注释的工作量\[23]。

### Y. Zhang et al

为了减轻手动标注的负担以应对这一挑战，人们已经付出了大量努力，致力于医学图像分割的注释高效深度学习方法\[24,27,28]。在这些方法中，半监督学习是一种更实用的方法，通过鼓励模型利用未标记数据，与有限数量的标记数据一起进行训练\[4]。半监督学习通常分为两种类型：基于伪标签的方法\[2,15,26]为未标记数据分配伪标签，并使用标记和伪标签数据训练模型，以及基于一致性学习的方法\[9,19,22,25]使用无监督的正则化方法从标记和未标记数据中进行学习。尽管这些方法可以通过利用未标记数据来提高性能，但在极度有限的注释场景下，与完全监督方法之间仍存在差距。

最近，诸如Segment Anything Model (SAM) \[5]之类的分割基础模型凭借其在各种语义分割任务中的强大泛化能力引起了广泛关注\[7,18]。尽管最近的研究揭示了由于自然图像和医学图像之间的差异，SAM在医学图像分割中的性能有限\[11,21]，但当手动标注的图像稀缺时，它仍然作为可靠的伪标签生成器为分割任务开辟了新的机会\[8]。

在本文中，我们提出了一种简单而高效的策略，**探索SAM作为额外的监督分支来增强基于一致性学习的半监督医学图像分割框架，在极度有限的注释场景下使用。**具体而言，分割模型提供定位信息并生成提示点给SAM。除了基于有标记样本的监督分割损失和基于无标记样本的无监督一致性损失来优化分割模型之外，我们还利用SAM和分割模型之间的预测一致性作为额外的监督信号来辅助学习过程。通过在Left Atrium (LA)数据集\[17]上进行实验，**基于两个半监督学习框架，SAM的辅助显著提高了分割性能，特别是当只有一张或几张有标记的图像可用时。**

## 方法

我们提出的SAM增强的半监督分割框架的结构如图1所示。半监督框架（这里我们以mean teacher框架\[14]为例）主要由两个组件组成：主分支和分割网络，用于输入原始图像并生成主要分割输出（即mean teacher的学生模型的输出），以及一致性分支，用于对输入图像或网络条件引入扰动（即从学生模型到mean teacher的教师模型的指数移动平均（EMA）），以生成额外的分割输出（即mean teacher的教师模型的输出）。

<figure><img src="../../../.gitbook/assets/image (3).png" alt=""><figcaption></figcaption></figure>

关于半监督分割任务，我们将有标记的数据集表示为 无标记数据

。。。。。

然而，当半监督学习只有一张或几张有标记的图像可用时，模型无法学习足够的领域知识来准确分割具有复杂结构的挑战性区域，而一致性学习的实施可能会导致模型生成“类似但不正确”的大多数目标预测，并忽略固有的信息。由于粗分割可以提供定位信息并生成SAM的提示点，我们采用了SemiSAM作为额外的监督分支，生成相对可靠的伪标签来指导学习过程。在现有的半监督框架基础上，利用主分支的输出来生成SemiSAM的输入提示。然后，我们计算主分割和SemiSAM之间的一致性损失Lsam。

{% embed url="https://arxiv.org/pdf/2312.06316.pdf" %}

