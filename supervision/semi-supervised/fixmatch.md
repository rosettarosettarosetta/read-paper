---
description: 它的主要创新来自于一致性正则化和伪标签方法的结合，以及在进行一致性正则化时使用独立的弱增强和强增强。
---

# FixMatch



对于无标签的样本，`FixMatch`：

* FixMatch首先对弱增强的无标签图像，预测伪标签\

*
  * 对于给定的图像，只有当模型产生高于阈值的预测时，才会保留作为伪标签

\


* 再对同一图像的强增强版本，预测出分类概率\

*
  * 通过交叉熵损失衡量，强弱二者的预测的一致性

\
FixMatch的核心：

* 一致性正则和伪标签方法的，简单组合
* 无标签模型预测，与UDA一样，采用RandAugment\[3]进行强增强



利用一张无标签样本，分别进行：

* “弱”增强（翻转、缩放）
* “强”增强（CutOut、CTAugment、RandAugment),



* 然后，通过model得到预测标签
* 并，通过标准交叉熵损失计算损失

\


上述“弱“增强方式预测过程，需要设定一个阈值大于阈值的才计算loss，小于的就不计算

相当于，在前期训练阶段中，无标签样本损失可能一直是为0的



<figure><img src="../../.gitbook/assets/image (1) (1).png" alt=""><figcaption></figcaption></figure>

## 论文摘要

将一个弱增强的图像（顶部）输入到模型中以获得预测结果（红色框）。**当模型对任何类别分配的概率高于一个阈值（虚线）时，将预测结果转换为一个独热伪标签（**a one-hot pseudo-label**）**。然后，我们计算模型对同一图像进行强增强后的版本的预测结果（底部）。通过**交叉熵损失**，训练模型使其在强增强版本上的预测结果与伪标签相匹配。



人工标签是基于一个**弱增强**的无标签图像产生的（例如，只使用翻转和平移数据增强），当模型输入同一图像的强增强版本时，这个弱增强的无标签图像被用作目标。



对于一个具有L个类别的分类问题，令X = (xb, pb) : b ∈ (1, . . . , B)表示一个包含B个标记示例的批次，其中xb是训练示例，pb是独热标签。令U = ub : b ∈ (1, . . . , µB)表示一个包含µB个无标签示例的批次，其中µ是一个超参数，用于确定X和U的相对大小。令pm(y | x)表示模型对输入x产生的预测类别分布。我们用H(p, q)表示两个概率分布p和q之间的交叉熵。作为FixMatch的一部分，我们进行两种类型的增强：**强增强和弱增强**，分别用A(·)和α(·)表示。





























\


{% embed url="https://arxiv.org/abs/2001.07685" %}
\\
{% endembed %}

[https://github.com/google-research/fixmatch](https://github.com/google-research/fixmatch)

## REFERENCE：

1\.

{% embed url="https://www.zhihu.com/question/457133996/answer/2672409953" %}



